

What about the span of a set that 
contains only one vector? 
That's the set of all scalar multiples of 
that vector, which we saw earlier, is the 
line through the origin and the point 
corresponding to that vector. 
It's a one-dimensional structure. 
What about the span of the empty set? 
We saw that this is just the origin. 
That's a zero-dimensional object. 
What about the span of 2-vectors? 
In this case, that gets you all the 
points in the plane. 
So, it's a two-dimensional object. 
What about the span of 3-vectors? 
Similarly, that's a plane in 
three-dimensions. 
Looks like this, a plane is a 
two-dimensional object. 
This raises the question: Is the span of 
k vectors always a k-dimensional 
geometric object? 
The answer is no. 
For example, the span of the 0-vector, 
consists just of the 0-vector. 
That's a zero dimensional geometric 
object. 
The span of these two vectors is a line 
which is a 1-dimensional geometric 
object. 
The span of these three vectors is, two 
dimensional object, 
a plane, which raises a fundamental 
question. Given k vectors 
how can we predict the dimensional of the 
geometric object that's formed by their 
span? 
So we've seen that the span of these two 
three vectors forms a plane in three 
space. 
And in fact, this is useful for plotting 
the plane. 
So here, here I've taken multiple choices 
of alpha and beta, and plotted what you 
could, what you get. 
So there's a more familiar representation 
of planes, which is this, the set of 
triples x, y, z, satisfying an equation 
of this form. 
Now, we can use vectors to represent the 
same equation. 
So the set of vectors x, y, z such that 
this dot product is equal to 0. 
So we're describing a set of vectors 
using a linear equation with a right hand 
side of zero. 
We can similarly a line in three 
dimensions 
by using two equations with right hand 
sides equal to 0. 
So it seems we have two ways to represent 
a geometric object such as a line or a 
plane. 
We can represent it as the span of some 
vectors or we can represent it as the 
solution set to a set of linear 
equations. 
Where the right-hand sides are 0. 
So we've got these two methods of 
representing things. 
One of the great themes of computer 
science is having multiple 
representations, is very often useful. 
And we'll see it's true in this case as 
well. 
So, for ex, here's a plane represented as 
the span of two vectors. 
And the same plane represented as the 
solution set to this linear equation with 
the right hand side equal to 0. 
Here's an example of a line, and this 
line can be represented as the span of 
this single vector. 
Or as the solution set of these two 
linear equations, with right hand sides 
equal to 0. 
Each of these representations has its 
uses. 
For example, suppose you have two lines, 
and you want to find the plane that 
contains those two lines. 
Let's say, the first line, is the span of 
this, set consisting of one vector. 
The second line is the span, of another 
set consisting of another vector. 
How would you find the plane containing both of 
them? 
Well, it turns out it's the span of those 
two vectors. 
So this representation is convenient for 
finding the geometric object containing 
two smaller dimension geometrical 
objects. 
Now, suppose I want to find the 
intersection of two planes. 
Now let's say I've represented one plane 
as the solution set of this linear 
equation. 
I've represented the other plane as the 
solution set of another linear equation. 
How can you find a representation of the 
line that is the intersection of these 
two planes? 
It turns out you want the, you want the 
points. 
The triples x, y, and z that satisfy both 
these equations. 
So, by using this representation, we can 
get the line that's the intersection of 
these two planes. 
What's common about these two 
representations for sets of vectors that 
form geometric objects? 
The subset of, in this case r to the d, 
satisfying three properties. 
The first is the subset contains the zero 
vector. 
The second is, if a subset contains some 
vector v, it contains every scalar 
multiple of that vector. 
And the third is, if the subset contains 
two vectors, u and v, it also contains 
their sum. 
So let's see why the span of a collection 
of vectors 
Satisfies these three properties. 
The first one is easy. The span of a, 
vectors V1 through Vn is the set of all 
linear combinations of those vectors. 
Here's one linear combination, where you 
take every coefficient to be zero. 
That obviously gives you the zero vector. 
So, property V1 is satisfied. 
What about property V2? 
Let's take any vector in the set that is 
a vector in the span which is a vector 
that can be written as a linear 
combination of V1 through VF. 
So we have a vector that's written as 
some linear combination. 
You have some scalar alpha. 
Then, the scala, vector product alpha 
, can be also written as a linear 
combination of those vectors V1 through 
Vn. 
You just multiply all the coefficients by 
alpha. 
Now for property V3. 
Property V3 states that if two vectors u 
and v are in the span then their sum is 
also in the span. 
So lets say u and v are in this span that 
means that u can be written as a linear 
combination and v can be written as 
another linear combination. 
Well then, we can represent their sum by 
just taking the linear combination where 
each coefficient is the sum of the 
corresponding coefficients in u and V. 
Now let's turn to the other 
representation, the solution set of the 
collection of linear equations where the 
right hand sides are all 0. 
Now property V1 is also easy. 
Take the 0 vector and plug it in, well a1 
dotted with a 0 vector is 0. 
A2 dotted with a 0 vector is 0 and so on, 
all of the dot products with a 0 vector 
are 0, so clearly the 0 vector lies in 
this solution set. 
Now let's turn to V2. 
Take some vector that's in the solution 
set, that is all these dot products are 
equal to zero. 
And now consider whether alpha times that 
vector also lies in the solution set. 
Well what's the dot-product? 
A1 dotted with alpha times V. 
That's the same as alpha times A1, dotted 
with V, which is alpha times zero, which 
is zero. 
So similarly, all thes linear equations 
also hold of alpha V. 
So that proves property V2. 
Now let's turn to property V3. 
Similarly, suppose you have 2 vectors, u 
and v, that lie in the solution set. 
Well, that means u and v satisfy all 
these linear equations. 
That is, the dot products are all zero. 
A1.u is zero, and so on, up to am.u is 
zero. 
And similarly, a1.v is zero, all the way 
up to am.v is zero. 
Well, then it's easy to see that the sum 
of u and v also lies in the solution set. 
Why is that? 
Let's look at the dot-product. 
A1 dot u plus v is the same as a1 dot u 
plus a1 dot v by the distributive law. 
A1 dot u is 0, a1 dot v is zero. 
Therefore their sum is also equal to 
zero. 
So this shows that all those equations 
also hold of the sum u plus v. 
Any subset big V of F to the D 
satisfying these three properties is 
called a vector space. 
So for example, we've shown that for any 
vectors V1 through Vn, the span of those 
vectors is a vector space. 
And for linear equations, a1.x equals 0 
up to am.x equals 0. 
The solution set of all these linear 
equations is a vector space as well. 
Now, if we have 2 sets, big U and big V, 
and they're both vector spaces, but U is 
a subset of V, we call U a subspace. 
So, for example, the span of V1 through 
Vn, and the solution set of these linear 
equations with right-hand side equals 0 
are subspaces of R to the D. 
Here's a fact that turns out to be not so 
hard, but quite essential to linear 
algebra. 
That every subspace of R to the D can be 
written in each of those two forms. 
Every subspace can be written as the span 
of some vectors and every subspace can be 
written as the solution set of the linear 
equations. 
Where the right-hand side equals 0. 
Now, a disclaimer. 
In a traditional, mathematical course on 
linear algebra, A more abstract course 
that we take a more abstract approach. 
So we wouldn't define vectors as 
sequences or functions. 
Instead, we would define a vector space 
to be any set that came along with an 
addition operation and a scaler 
multiplication operation. 
Any set that satisfied certain axioms and 
satisfied properties V1, V2 and V3. 
This approach has it's advantages. 
Any time you give a more abstract 
definition of something you don't have to 
be concerned with the internal structure 
details of the, of the thing. 
In this case, we don't have to be 
concerned. 
If we took this approach, we wouldn't 
have to be concerned with the internal 
structure of vectors. 
This is analogous to encapsulation or or 
information hiding in object oriented 
programming. 
The advantage is it's more general. 
Now, I didn't take this approach. 
I took a, a, a less abstract approach for 
this course, because I think in 
developing intuition about vectors. 
It's helpful to have this concrete 
representation. 
Now, much earlier, we saw that the u to v 
line segment could be represented in this 
way. 
It's the set of linear combinations, 
alpha u plus beta v, where alpha and beta 
are non negative and sum to 1. 
We say a linear combination of vectors V1 
through Vn is a convex combination if the 
coefficients all are non-negative and 
they sum to one. 
For example, the convex hull of a single 
vector is a point. 
The convex hull of two vectors is, 
generally, a line segment. 
And the convex hull of three vectors is a 
triangle. 
So you would think that the more vectors 
you have, the higher dimensional the 
object, that's not always true. 
For example if these three points are 
co-linear, they, they're in the same 
line, then their convex hull is a line 
segment. 
Similarly, if you have a bunch of points 
and they're all on the same plane then 
their convex hull forms a polygon. 

